{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3 as lite\n",
    "engine = lite.connect('db.sqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_contain_chinese(check_str):\n",
    "    for ch in check_str:\n",
    "        if u'\\u4e00' <= ch <= u'\\u9fa5':\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_category_list():\n",
    "    HOST = 'https://tw.buy.yahoo.com'\n",
    "    res = requests.get(HOST+'/help/helper.asp?p=sitemap')\n",
    "    res.encoding = 'big5'\n",
    "    soup = BeautifulSoup(res.text,'lxml')\n",
    "    a_tag = soup.select('#cl-sitemap a')\n",
    "    category = []\n",
    "    href = []\n",
    "    for a in a_tag:\n",
    "        category.append(a.text)\n",
    "        href.append(HOST+a['href'])\n",
    "    df_category = pd.DataFrame(columns=['category','url'])\n",
    "    df_category['category'] = category\n",
    "    df_category['url'] = href\n",
    "    df_category = df_category[df_category['url'].str.contains('sub')]\n",
    "    return df_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_category = crawl_category_list()\n",
    "df_category.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_category.to_sql('yahoo_category', con=engine, if_exists='append', index=False)\n",
    "cur = engine.cursor()\n",
    "cur.execute('SELECT * FROM yahoo_category;').fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_product_list(category_url):\n",
    "    res = requests.get(category_url)\n",
    "    soup = BeautifulSoup(res.text,'lxml')\n",
    "    a_tag = soup.select(\"a\")\n",
    "    href = []\n",
    "    for a in a_tag:\n",
    "        try:\n",
    "            test = a['href']\n",
    "            href.append(a['href'])\n",
    "        except KeyError as e:\n",
    "            pass\n",
    "    df_products = pd.DataFrame(columns=['product_title','url'])\n",
    "    df_products['url'] = href\n",
    "    \n",
    "    #取出為商品頁的連結\n",
    "    chinese = []\n",
    "    for i in range(0,len(df_products)):\n",
    "        chinese.append(check_contain_chinese(df_products.loc[i]['url']))\n",
    "    product_list = df_products[chinese].url.unique()\n",
    "    return product_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list = crawl_product_list(df_category.loc[1]['url'])\n",
    "product_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_product(product_url,category,position):\n",
    "    try:\n",
    "        res = requests.get(product_url)\n",
    "        soup = BeautifulSoup(res.text,'lxml')\n",
    "        price = soup.select('.price')\n",
    "        real_price = -1\n",
    "        try:\n",
    "            title = soup.select('h1')[0].text\n",
    "        except:\n",
    "            title = '產品名稱無法抓取'\n",
    "        for p in price:\n",
    "            try:\n",
    "                real_price = int(p['content'])\n",
    "            except KeyError as e:\n",
    "                pass\n",
    "        product = [title,category,real_price,position,product_url]\n",
    "        return product\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = crawl_product(product_list[0],df_category.loc[1]['category'],0)\n",
    "product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_category_product(category_title, category_url):\n",
    "    df_category_products = pd.DataFrame(columns=['product','category','price','position','url'])\n",
    "    product_list = crawl_product_list(category_url)\n",
    "    for idx, product_url in enumerate(product_list):\n",
    "        df_category_products.loc[idx] = crawl_product(product_url,category_title,idx)\n",
    "    return df_category_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list = crawl_category_list()\n",
    "category_list.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    df_category_products = get_all_category_product(category_list.loc[i]['category'],category_list.loc[i]['url'])\n",
    "    df_category_products.to_sql('yahoo_product', con=engine, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
